{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Experiment to check how a Random Forest Classifier reacts against\n",
    "modifications in the synthetic testing datasets.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from data import load_csv_to_df, train_test_split_stratify\n",
    "from graph import get_flow_features_values, get_encoded_label\n",
    "import configparser\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from data import modify_portscan_attack_behavior\n",
    "import os\n",
    "import metrics\n",
    "#!pip install plotly\n",
    "\n",
    "# import libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, re, time, math, tqdm, itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dev/src\n",
      "train_data label rate  Label\n",
      "PortScan    101715\n",
      "BENIGN       81623\n",
      "Name: count, dtype: int64\n",
      "\n",
      "test_data label rate  Label\n",
      "PortScan    25429\n",
      "BENIGN      20406\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "source_code_dir = '/home/dev/src'\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(source_code_dir+\"/config.ini\")\n",
    "\n",
    "\n",
    "data = load_csv_to_df(\n",
    "    config[\"PARAMETERS\"][\"DataFolderPath\"] + config[\"PARAMETERS\"][\"TrainFile\"])\n",
    "\n",
    "# test = load_csv_to_df(\n",
    "#     config[\"PARAMETERS\"][\"DataFolderPath\"] + config[\"PARAMETERS\"][\"EvalFile\"])\n",
    "\n",
    "# 데이터 셋 분리 \n",
    "train,test  = train_test_split_stratify(data,0.3)\n",
    "\n",
    "print('train_data label rate',train[' Label'].value_counts())\n",
    "print()\n",
    "print('test_data label rate',test[' Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_map = {\"BENIGN\": 0, \"PortScan\": 1}\n",
    "labels = [\"BENIGN\", \"MALIGN\"]\n",
    "\n",
    "flow_features = [    \n",
    "    \" Flow Duration\",\n",
    "    \" Flow Packets/s\",\n",
    "    \" Flow IAT Mean\",\n",
    "    \" Fwd IAT Mean\",\n",
    "    \" Bwd IAT Mean\",]\n",
    "\n",
    "# flow_features = [\n",
    "#     \" Average Packet Size\",\n",
    "#     \" Flow IAT Mean\",\n",
    "#     \" Flow Duration\",\n",
    "# ]\n",
    "\n",
    "\n",
    "test = modify_portscan_attack_behavior(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train vectors\n",
    "x_train = []\n",
    "y_train = []\n",
    "for _, row in train.iterrows():\n",
    "    x_train.append(get_flow_features_values(row, flow_features))\n",
    "    y_train.append(get_encoded_label(\n",
    "        row, labels_map))\n",
    "\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "# test vectors\n",
    "x_test = []\n",
    "y_test = []\n",
    "for _, row in test.iterrows():\n",
    "    x_test.append(get_flow_features_values(row, flow_features))\n",
    "    y_test.append(get_encoded_label(\n",
    "        row, labels_map))\n",
    "\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.6600e+02, 4.2918e+03, 4.6600e+02, 0.0000e+00, 0.0000e+00],\n",
       "        [3.8000e+01, 5.2632e+04, 3.8000e+01, 0.0000e+00, 0.0000e+00],\n",
       "        [1.1000e+01, 1.8182e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00],\n",
       "        ...,\n",
       "        [7.4000e+01, 2.7027e+04, 7.4000e+01, 0.0000e+00, 0.0000e+00],\n",
       "        [6.7000e+01, 2.9851e+04, 6.7000e+01, 0.0000e+00, 0.0000e+00],\n",
       "        [7.2000e+01, 2.7778e+04, 7.2000e+01, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dummie = np.array(pd.get_dummies(y_train,dtype=int))\n",
    "y_test_dummie = np.array(pd.get_dummies(y_test,dtype=int))\n",
    "\n",
    "x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,activation='relu', input_shape=(5,1)))\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The first argument to `Layer.call` must always be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/dev/src/train_dnn.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7466227d/home/dev/src/train_dnn.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m model()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7466227d/home/dev/src/train_dnn.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7466227d/home/dev/src/train_dnn.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39mbest_model.h5\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/layer_utils.py:969\u001b[0m, in \u001b[0;36mCallFunctionSpec.split_out_first_arg\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m     inputs \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_arg_names[\u001b[39m0\u001b[39m])\n\u001b[1;32m    968\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    970\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe first argument to `Layer.call` must always be passed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    971\u001b[0m     )\n\u001b[1;32m    972\u001b[0m \u001b[39mreturn\u001b[39;00m inputs, args, kwargs\n",
      "\u001b[0;31mValueError\u001b[0m: The first argument to `Layer.call` must always be passed."
     ]
    }
   ],
   "source": [
    "model = model()\n",
    "model.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(x_train, y_train_dummie, epochs=20, batch_size=128, validation_data=(x_test, y_test_dummie), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F1 Score': 0.962571317519216,\n",
       " 'Accuracy': 0.9633249700010909,\n",
       " 'Recall': 0.9592951347120982,\n",
       " 'Precision': 0.9679822953069751}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Evaluating model...\")\n",
    "\n",
    "print(model.score(x_test, y_test))\n",
    "\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "metrics.compute_metrics(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
